\chapter{绪论}\label{chap:introduction}

\section{研究背景及国内外研究现状}

卷积神经网络(CNN)现在是许多学科研究的热点之一，被广泛用于多种领域，特别是在模式识别、图像处理、计算机视觉等方面。但是卷积神经网络的主要问题在于计算量太大，特别是其中的卷积层，以Alex-Net为例，占用了90\%\citep{chen2016eyeriss} 以上的计算量，卷积神经网络的硬件加速逐渐成为一个热门的研究问题。由于卷积神经网络自身特点，层与层之间可以看做顺序执行，而层内则有着较高的并行性，因此提高层内计算的并行度成为加速卷积神经网络的一个重要方向。

在2009，Farabet等人提出来一种基于FPGA的CNN，该结构使用卷积单元来处理数据，并使用一个通用CPU来控制卷积单元\citep{farabet2009cnp}。但是由于FPGA资源的限制，该平台只实现了一个卷积核。如果计算需要多个卷积核，那么只能串行执行。2013年，Peemen等人实现了一个以存储为中心的CNN协处理器，它利用CNN大量内存访问的特点，在存储部分使用SRAM，而PE部分使用SIMD指令\citep{peemen2013memory}。2015年，清华大学的方睿等人，提出一种多级流水线的管道加速器方案。CPU通过PCIE通道提供数据并控制整个逻辑单元。近年来，中科院的陈天石等人提出来DianNao系列的加速器，目前是卷积神经网络硬件加速领域的较优的一种方案，可以实现多种结构的卷积网络，如MLP、CNN、DNN\citep{chen2014diannao}。纯硬件实现的卷积神经网络加速器通用性不好。尽管可以通过配置来实现更多的结构，但是它的灵活性远不如通用CPU。因此可重构加速器与通用CPU相结合的模式是一种高效地解决卷积神经网络加速问题的方案。

但是在这种定制结构中，CPU的选择具有极大的挑战。通常商业授权的IP会限制对指令集的修改，影响卷积神经网络加速器的实现效果。并且商业授权的IP通常需要高昂的授权费，不利于高校和个人的研究。因此需要一个开源的指令集架构来进行定制加速器的研究。

RISC-V是一种新的开源指令集架构（ISA）\citep{waterman2011risc}，目前已经有了一个完整的硬件和硬件生态\citep{asanovic2014instruction}，包括完整的指令集、相应的编译器、模拟器和工具链。利用开源的RISC-V处理器，研究人员可以方便地将可重构加速器整合进SOC，并拓展相应的指令集来实现加速器的软件接口。

% \section{设计目标及平台的选择}

% 本设计主要包含三个部分，RISC-V Core和卷积神经网络加速器，以及将两部分结合起来实现完整功能的SOC部分。卷积神经网络的硬件加速通常可以采用ASIC或者FPGA来实现，两者均是采用定制的硬件电路来加速算法。通常ASIC的性能跟高，功耗更低，但是由于成本过高，因此在本设计中采用FPGA作为硬件平台。

% 本设计在第五章中提出来一种使用 ZYNQ 芯片上运行 Linux 系统与 RISC-V 处理器共享内存的方法来解决一些 RISC-V 处理器缺少调试接口，不方便调试和下载程序的方法。考虑各方面因素，最终选取了 PYNQ-Z2 作为硬件平台。 PYNQ-Z2 上使用Xilinx ZYNQ 7020芯片。芯片包含了 13,300 个可编程逻辑单元，每个逻辑单元有4个6输入查找表和8个触发器。芯片有 630 KB 的块存储器，220 个 DSP 运算单元，逻辑资源相对丰富。开发板引出数十个 IO 口和一个 HDMI 接口，拥有 512MB 的 DDR3，足够该系统使用。

\section{研究意义及前景}

卷积神经网络作为目前深度学习的一个重要手段，由于计算量巨大的问题限制了其应用场景，通常需要在高性能的运算平台上进行模型的推演，因此主要被应用在主机场景，而非便携式应用。而利用卷积神经网络层内并行的特点，对卷积神经网络进行硬件加速，从而极大地提高了卷积网络的运行速度，使得便携式低功耗设备也可以进行卷积神经网络运算，极大地拓展了深度学习的应用场景。

\section{研究内容及结构安排}

本文主要在 FPGA 平台上设计并实现了一种卷积神经网络加速器结构，并通过 RISC-V 处理器完成流程控制和一部分运算任务。通过软件配置的方法来调整卷积神经网络加速器网络的结构，使其具有一定的通用性。通过对卷积神经网络模型的分析，划分计算任务。将不同的任务使用 FPGA 进行加速，分析加速的效果，最终得到一种效果最好的加速器优化方案。

本文共有七个章节，论文结构安排如下：

第一章：主要介绍了课题的研究背景及研究意义，结合国内外研究现状，分析使用 FPGA 加速神经网络算法的所遇到的问题，并提出本文的研究方向。

第二章：主要对本文研究所涉及到的相关技术背景的介绍，首先介绍了人工神经网络，并对本文所使用的算法——YOLO V2 算法进行了详细的分析，同时介绍了 RISC-V 处理器相关的背景以及在本系统中为何选用 RISC-V 处理器。

第三章：总体介绍了系统的设计思路：先对 YOLO V2 算法进行了详细的分析，结合 FPGA 与 CPU 各自的特点，对整个神经网络算法的加速进行了任务划分，并给出本设计所使用的逻辑结构。

第四章：对 CNN 加速器进行详细设计及优化，介绍了使用 HLS 设计 CNN 加速器过程中的优化方案以及具体应用情况。

第五章：由于 CNN 加速器需要配合 RISC-V 软核进行异构运算，因此本章将 CNN 加速器作为 RISC-V 处理器的外设，设计了一个通用 RISC-V SOC，介绍了该 SOC 的硬件架构以及详细设计过程。

第六章：主要计算分析了 CNN 加速器的资源消耗，结合常见的运算平台，设计了3组典型的对照环境，将本设计中的异构计算系统与其分别进行对比，分析了该异构计算系统的优缺点。

第七章：总结全文的研究内容，对本课题中可以进一步研究的方向进行讨论。



