%---------------------------------------------------------------------------%
%->> Frontmatter
%---------------------------------------------------------------------------%
%-
%-> 生成封面
%-
\maketitle% 生成中文封面
% \MAKETITLE% 生成英文封面
%-
%-> 作者声明
%-
% \makedeclaration% 生成声明页
%-
%-> 中文摘要
%-
% \intobmk\chapter*{摘要}% 显示在书签但不显示在目录
% syntax: \chapter[目录]{标题}\chaptermark{页眉}
\chapter[摘要]{\MyTitleCh}\chaptermark{摘要}
\setcounter{page}{1}% 开始页码
\pagenumbering{Roman}% 页码符号

\begin{center}
\vspace{-0.3cm}
\zihao{3} \songti 摘要
\vspace{0.3cm}
\end{center}

近年来，深度神经网络已经被证明在包括图像分类、目标检测和自然语言处理等任务上能够取得相当不错的效果。现如今，大量的应用程序都配备了与之相关的深度学习算法，但是对于手机、无人机等资源有限的嵌入式设备上，仅用软件方式加速深度神经网络已经不能满足日益增长的速度和功耗要求，如何利用硬件设计加速器已经成为学术领域的研究热点。

本文首先给出了深度神经网络的概述，并介绍了几种当下主流的针对深度神经网络的硬件加速系统设计方案以及实际应用。之后，本文将对英伟达开源的深度学习加速器框架NVDLA的设计思路进行概述。然后，本文基于 ZYNQ 7000 器件，在 FPGA 端实现了 NVDLA 设计，通过 AXI4 总线协议将 NVDLA 加速器挂载到 ARM A9 处理器，并为 ARM A9 处理器移植了 Ubuntu 16.04 操作系统，将加速器的驱动程序加载到了 Linux 内核。在软件设计的前端，使用神经网络编译器接受预训练的深度神经网络模型，结合TensorRT完成了深度神经网络的量化，在软件设计的后端，由 Runtime 自动调度加速器驱动程序推理深度神经网络，打通了硬件栈与软件栈，完成了软件与硬件的协同设计。

{
    \zihao{5}
    \keywords{深度神经网络 \quad FPGA \quad NVDLA \quad 硬件加速}% 中文关键词
}
%-
%-> 英文摘要
%-
% \intobmk\chapter*{Abstract}% 显示在书签但不显示在目录
\chapter[Abstract]{\MyTitleEn}\chaptermark{Abstract}

\begin{center}
\vspace{-0.3cm}
\zihao{3} \songti Abstract
\vspace{0.3cm}
\end{center}

In recent years, deep neural networks have been proven to achieve quite good results in tasks including image classification, target detection, and natural language processing. Nowadays, a large number of applications are equipped with related deep learning algorithms. However, for embedded devices with limited resources such as mobile phones and drones, the use of software to accelerate deep neural networks can no longer meet the increasing speed and Power consumption requirements, how to use hardware design accelerators have become a research hotspot in the academic field.

This article first gives an overview of deep neural networks, and introduces several current mainstream hardware acceleration system design schemes and practical applications for deep neural networks. This design first refers to CNNIOT and uses HLS to build a general convolutional neural network hardware accelerator, which realizes the acceleration of the Lenet5 network, and uses Bootstrap to design a user-friendly interactive page. After that, this article will give an overview of the design ideas of Nvidia's open source deep learning accelerator framework NVDLA. Then, based on the ZYNQ 7000 device, this article implements the NVDLA design on the FPGA side, mounts the NVDLA accelerator to the ARM A9 processor through the AXI4 bus protocol, and transplants the Ubuntu 16.04 operating system for the ARM A9 processor, and loads the accelerator driver To the Linux kernel. At the front end of the software design, the neural network compiler is used to receive the pre-trained deep neural network model, combined with TensorRT to complete the quantization of the deep neural network. At the back end of the software design, the Runtime automatically schedules the accelerator driver to infer the deep neural network and get through The hardware stack and software stack are completed, and the collaborative design of software and hardware is completed.

\KEYWORDS{Deep neural network; FPGA; NVDLA; Hardware speedup}% 英文关键词
%---------------------------------------------------------------------------%
