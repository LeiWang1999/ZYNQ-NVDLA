\chapter{总结与展望}\label{chap:conclusion}

总的来说，本设计的重点是将原本面向 ASIC 设计的 NVDLA 移植到 FPGA 上进行验证，学习了其自上而下且规范的设计方法。对于已经停止维护的，最新版本的 NVDLA 到 FPGA 的映射过程，在本设计之前并没有检索到相关的工作。NVDLA 于 2017 年开源发布，实际的研发时间应该在 2015 至 2016年开始，所以其整体的结构于 DianNao、DaDianNao 类似，但相比于当下的深度学习加速器体系结构来说，还是有些落后的。例如在 DaDianNao 之后，中科院计算技术研究所又提出了深度神经网络专用的指令集\cite{7551409}。

根据设计的结果来看，在 FPGA 上的实现的 NVDLA 的速度可观，在打通软件栈之后其能够推理任意复杂，具备支持算子的网络模型，但由于时间有限，还有许多可以进一步研究的地方：

\begin{enumerate}
    \item NVDLA 内部运算的核心是 MAC 阵列，但是由于其是面向 ASIC 设计，MAC 阵列在 FPGA 上映射到了 LUT 查找表资源，这会导致运行效率的低下，而根据资源利用情况来看，可以将 MAC 阵列消耗转化为片上的 DSP 资源以进一步提高效率。
    \item 基于现有的研究\cite{祁琛2018应用于神经网络的高效能计算单元的研究与实现}，优化 NVDLA 的 MAC 运算。
    \item 针对不支持的算子，例如目标检测网络中的 RPN 算子、反卷积算子，NVDLA 不会工作，可以自行增加软件栈的特性，使这些不被硬件加速器支持的算子由软件实现。
    \item 官方开源的 NVDLA 软件栈仅支持 Caffemodel，而现有的其他支持 NVDLA 作为后端的深度神经网络编译器，如 ONNC 可以支持 ONNX 生成 Loadable 文件，极大增加了灵活性。
\end{enumerate}
