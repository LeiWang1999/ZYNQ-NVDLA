\chapter{总结与展望}\label{chap:conclusion}

总的来说，本设计的重点是将原本面向 ASIC 设计的 NVDLA 移植到 FPGA 上进行验证，学习了其自上而下且规范的设计方法。对于已经停止维护的，最新版本的 NVDLA 到 FPGA 的映射过程，并没有检索到相关的工作。NVDLA 于 2017 年开源发布，实际的研发时间应该在 2015 至 2016年开始，所以其整体的结构于 DianNao、DaDianNao 类似，但相比于当下的深度学习加速器体系结构来说，还是有些落后的。例如在 DaDianNao 之后，中科院计算技术研究所又提出了深度神经网络专用的指令集。

根据设计的结果来看，在 FPGA 上的实现的 NVDLA 的速度一般，但在打通软件栈之后其能够推理任意复杂，具备支持算子的网络模型，但由于时间有限，还有许多可以进一步研究的地方：

\begin{enumerate}
    \item NVDLA 内部运算的核心是 MAC 阵列，但是由于其是面向 ASIC 设计，MAC 阵列为行为及描述，在 FPGA 上映射到了 LUT 查找表资源，这会导致 MAC 阵列的运行效率低下。
    \item 基于现有的研究\cite{祁琛2018应用于神经网络的高效能计算单元的研究与实现}，优化 NVDLA 的 MAC 阵列。
    \item 针对不支持的算子，例如目标检测网络中的 RPN 算子、反卷积算子，NVDLA 不会工作，可以自行增加软件栈的特性，使这些不被硬件加速器支持的算子由软件实现。
\end{enumerate}